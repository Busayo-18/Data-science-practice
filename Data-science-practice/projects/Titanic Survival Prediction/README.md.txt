
Titanic Survival Prediction 

------

***Kaggle Titanic Competition Submission – Public Accuracy: 77.03%

Predicting passenger survival on the Titanic using feature engineering and a stacked ensemble of:

-Logistic Regression

-Random Forest

-XGBoost


------

***Highlights

-Created new features like Age Group and family size.

-Handled missing values and encoded categorical variables.

-Built a stacked ensemble for improved predictions.

-Evaluated with accuracy, precision, recall, F1-score, and ROC AUC.

-Developed and run entirely in Google Colab for reproducibility.

------

***Dataset

-Source: Kaggle Titanic Dataset

-Includes train.csv, test.csv, and gender_submission.csv (sample submission).

------

***How to Run in Google Colab

-Open Google Colab: https://colab.research.google.com

-Upload your notebook (Titanic.ipynb) or open from GitHub: File → Open Notebook → GitHub → Paste repo URL

-Upload the data/ folder (train.csv & test.csv) to Colab.

-Run all cells to preprocess data, train models, and generate submission.csv for Kaggle.

------

***Folder Structure
Titanic Survival Prediction/
├── notebooks/     # Jupyter/Colab notebooks
├── submission.csv # Example submission
├── README.md      # This file


------

***Technologies

Python | pandas | numpy | scikit-learn | xgboost | matplotlib | seaborn |Logistic Regression| Random Forest | Google Colab

-----

***Author

Olagunju Amina – Data Science & Machine Learning Enthusiast | Kaggle Competitor